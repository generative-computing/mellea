{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# External Validation API\n",
    "\n",
    "This notebook demonstrates Mellea's **External Validation API** - a high-level interface for validating outputs from external LLM frameworks (LangChain, OpenAI SDK, etc.).\n",
    "\n",
    "## The Problem\n",
    "\n",
    "When using external LLM frameworks like LangChain or the OpenAI SDK, you get outputs in their native formats (LangChain messages, OpenAI dicts, etc.). To validate these outputs with Mellea, you previously needed to:\n",
    "\n",
    "1. Convert messages to Mellea format manually\n",
    "2. Wrap outputs in `ModelOutputThunk`\n",
    "3. Build a `ChatContext` with the converted messages\n",
    "4. Start a Mellea session and call `m.validate()`\n",
    "\n",
    "This was verbose and error-prone (see the [LangChain IVR notebook](langchain_mellea_ivr.ipynb) for the manual approach).\n",
    "\n",
    "## The Solution\n",
    "\n",
    "The **External Validation API** (`mellea.stdlib.interop`) provides:\n",
    "\n",
    "- `external_validate()` - One-shot validation with automatic format detection\n",
    "- `ExternalSession` - Session-based validation with factory methods\n",
    "- `external_ivr()` - Full Instruct-Validate-Repair loop helper\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup](#setup)\n",
    "2. [Quick Start: external_validate()](#quick-start)\n",
    "3. [Session-Based Validation](#session-based)\n",
    "4. [Full IVR Loop](#ivr-loop)\n",
    "5. [Supported Formats](#formats)\n",
    "6. [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"setup\"></a>\n",
    "## Setup\n",
    "\n",
    "First, let's import the necessary modules and set up a backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed\n",
    "%pip install mellea langchain langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mellea import external_validate, ExternalSession\n",
    "from mellea.stdlib.interop import external_ivr, IVRResult\n",
    "from mellea.stdlib.requirements import req, simple_validate\n",
    "from mellea.backends import OllamaBackend\n",
    "\n",
    "# Optional: LangChain for examples\n",
    "try:\n",
    "    from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "    HAS_LANGCHAIN = True\n",
    "except ImportError:\n",
    "    HAS_LANGCHAIN = False\n",
    "    print(\"LangChain not installed - LangChain examples will be skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a backend for validation\n",
    "# You can use any Mellea backend (Ollama, OpenAI, Anthropic, etc.)\n",
    "backend = OllamaBackend(model=\"granite4:micro\")\n",
    "print(f\"Using backend: {backend}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"quick-start\"></a>\n",
    "## Quick Start: external_validate()\n",
    "\n",
    "The simplest way to validate external output is with `external_validate()`. It accepts:\n",
    "\n",
    "- **output**: String, OpenAI dict, LangChain message, or Mellea Message\n",
    "- **requirements**: List of strings (LLM-as-judge) or `Requirement` objects\n",
    "- **backend**: A Mellea backend for LLM-based validation\n",
    "- **context** (optional): Conversation history in any supported format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Validate a simple string output\n",
    "output = \"The capital of France is Paris. It's known for the Eiffel Tower.\"\n",
    "\n",
    "results = external_validate(\n",
    "    output=output,\n",
    "    requirements=[\"Must mention a city name\", \"Must be factually correct\"],\n",
    "    backend=backend,\n",
    ")\n",
    "\n",
    "print(\"String Output Validation:\")\n",
    "for i, result in enumerate(results):\n",
    "    status = \"PASS\" if result.as_bool() else \"FAIL\"\n",
    "    print(f\"  [{status}] Requirement {i + 1}\")\n",
    "    if result.reason:\n",
    "        print(f\"          Reason: {result.reason}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Validate with programmatic requirements\n",
    "output = \"The answer is 42.\"\n",
    "\n",
    "results = external_validate(\n",
    "    output=output,\n",
    "    requirements=[\n",
    "        # Programmatic validation with simple_validate\n",
    "        req(\n",
    "            \"Must contain a number\",\n",
    "            validation_fn=simple_validate(lambda x: any(c.isdigit() for c in x)),\n",
    "        ),\n",
    "        # LLM-as-judge validation (string requirement)\n",
    "        \"Must provide an explanation\",\n",
    "    ],\n",
    "    backend=backend,\n",
    ")\n",
    "\n",
    "print(\"Mixed Validation (Programmatic + LLM):\")\n",
    "print(\n",
    "    f\"  [{'PASS' if results[0].as_bool() else 'FAIL'}] Contains number (programmatic)\"\n",
    ")\n",
    "print(f\"  [{'PASS' if results[1].as_bool() else 'FAIL'}] Has explanation (LLM-judged)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Validate OpenAI-format output\n",
    "openai_response = {\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": \"I'd be happy to help you with that task!\",\n",
    "}\n",
    "\n",
    "results = external_validate(\n",
    "    output=openai_response, requirements=[\"Must be polite and helpful\"], backend=backend\n",
    ")\n",
    "\n",
    "print(f\"OpenAI Format Validation: [{'PASS' if results[0].as_bool() else 'FAIL'}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Validate with conversation context\n",
    "context = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a math tutor.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 15 + 27?\"},\n",
    "]\n",
    "\n",
    "output = \"15 + 27 = 42\"\n",
    "\n",
    "results = external_validate(\n",
    "    output=output,\n",
    "    requirements=[\"Must answer the user's question\", \"Must show the calculation\"],\n",
    "    backend=backend,\n",
    "    context=context,\n",
    ")\n",
    "\n",
    "print(\"Validation with Context:\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"  [{('PASS' if result.as_bool() else 'FAIL')}] Requirement {i + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"session-based\"></a>\n",
    "## Session-Based Validation with ExternalSession\n",
    "\n",
    "`ExternalSession` provides a class-based interface for validation with convenient factory methods:\n",
    "\n",
    "- `ExternalSession.from_output()` - Create from any output format\n",
    "- `ExternalSession.from_openai()` - Create from OpenAI message list\n",
    "- `ExternalSession.from_langchain()` - Create from LangChain message list\n",
    "\n",
    "This is useful when you want to:\n",
    "- Validate multiple requirement sets against the same output\n",
    "- Access the `output` property directly\n",
    "- Use the convenience `all_passed()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a session from a string output\n",
    "session = ExternalSession.from_output(\n",
    "    output=\"The meeting is scheduled for 3pm tomorrow.\", backend=backend\n",
    ")\n",
    "\n",
    "print(f\"Session output: {session.output}\")\n",
    "\n",
    "# Validate with the session\n",
    "results = session.validate([\"Must mention a time\", \"Must be about scheduling\"])\n",
    "\n",
    "print(f\"\\nValidation Results:\")\n",
    "for i, r in enumerate(results):\n",
    "    print(f\"  [{('PASS' if r.as_bool() else 'FAIL')}] Requirement {i + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a session from OpenAI-format messages\n",
    "openai_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a joke.\"},\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Why did the scarecrow win an award? Because he was outstanding in his field!\",\n",
    "    },\n",
    "]\n",
    "\n",
    "session = ExternalSession.from_openai(openai_messages, backend)\n",
    "\n",
    "print(f\"Output (auto-detected from last assistant message):\")\n",
    "print(f\"  '{session.output}'\")\n",
    "\n",
    "# Use all_passed() for a simple boolean check\n",
    "is_valid = session.all_passed([\"Must be a joke\", \"Must be family-friendly\"])\n",
    "print(f\"\\nAll requirements passed: {is_valid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a session from LangChain messages (if available)\n",
    "if HAS_LANGCHAIN:\n",
    "    lc_messages = [\n",
    "        SystemMessage(content=\"You are a travel assistant.\"),\n",
    "        HumanMessage(content=\"What's a good destination for beach lovers?\"),\n",
    "        AIMessage(\n",
    "            content=\"I recommend Bali, Indonesia! It has beautiful beaches, great surfing, and amazing cultural experiences.\"\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    session = ExternalSession.from_langchain(lc_messages, backend)\n",
    "\n",
    "    print(f\"Output (from LangChain AIMessage):\")\n",
    "    print(f\"  '{session.output}'\")\n",
    "\n",
    "    results = session.validate(\n",
    "        [\"Must recommend a specific destination\", \"Must mention beaches\"]\n",
    "    )\n",
    "\n",
    "    print(f\"\\nValidation:\")\n",
    "    for i, r in enumerate(results):\n",
    "        print(f\"  [{('PASS' if r.as_bool() else 'FAIL')}] Requirement {i + 1}\")\n",
    "else:\n",
    "    print(\"Skipping LangChain example (langchain not installed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"ivr-loop\"></a>\n",
    "## Full IVR Loop with external_ivr()\n",
    "\n",
    "The `external_ivr()` function implements a complete Instruct-Validate-Repair loop for external LLMs. It:\n",
    "\n",
    "1. **Instruct**: Calls your generation function\n",
    "2. **Validate**: Checks requirements using Mellea\n",
    "3. **Repair**: If validation fails, adds a repair prompt and retries\n",
    "\n",
    "This is useful when you want to ensure outputs meet requirements, with automatic retries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mellea.stdlib.components import Message\n",
    "import random\n",
    "\n",
    "\n",
    "# Simulate an external LLM that sometimes fails requirements\n",
    "def mock_generate(messages: list[Message]) -> str:\n",
    "    \"\"\"Simulated LLM that generates responses.\n",
    "\n",
    "    In real usage, this would call your LangChain agent, OpenAI API, etc.\n",
    "    \"\"\"\n",
    "    # Check if this is a retry (repair message in context)\n",
    "    is_retry = any(\n",
    "        \"requirements\" in m.content.lower() for m in messages if m.role == \"user\"\n",
    "    )\n",
    "\n",
    "    if is_retry:\n",
    "        # On retry, always include required elements\n",
    "        return \"The random number is 8. Welcome to the AI Foundations team!\"\n",
    "    else:\n",
    "        # First attempt might fail\n",
    "        num = random.randint(1, 10)\n",
    "        team = random.choice([\"AI Foundations\", \"Quantum Plus AI\"])\n",
    "        return f\"The random number is {num}. Welcome to the {team} team!\"\n",
    "\n",
    "\n",
    "print(\"Simulated generation (first call):\")\n",
    "print(\n",
    "    f\"  '{mock_generate([Message(role='user', content='Generate a number and team.')])}'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the IVR loop\n",
    "initial_context = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Generate a random number and tell me what team I'm on.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "requirements = [\n",
    "    req(\n",
    "        \"The number must be greater than 5\",\n",
    "        validation_fn=simple_validate(\n",
    "            lambda x: any(n in x for n in [\"6\", \"7\", \"8\", \"9\", \"10\"])\n",
    "        ),\n",
    "    ),\n",
    "    \"Must mention the AI Foundations team\",\n",
    "]\n",
    "\n",
    "result = external_ivr(\n",
    "    generate_fn=mock_generate,\n",
    "    requirements=requirements,\n",
    "    backend=backend,\n",
    "    initial_context=initial_context,\n",
    "    loop_budget=5,\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"IVR Result:\")\n",
    "print(f\"  Success: {result.success}\")\n",
    "print(f\"  Attempts: {result.attempts}\")\n",
    "print(f\"  Final output: '{result.output}'\")\n",
    "print(f\"\\nAll outputs generated:\")\n",
    "for i, out in enumerate(result.all_outputs, 1):\n",
    "    print(f\"  {i}. '{out}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom repair prompt function\n",
    "def custom_repair_prompt(failed_reqs, output):\n",
    "    \"\"\"Generate a custom repair prompt.\"\"\"\n",
    "    failed_descriptions = [req.description for req, _ in failed_reqs]\n",
    "    return (\n",
    "        f\"IMPORTANT: Your response '{output[:50]}...' did not meet these requirements:\\n\"\n",
    "        f\"- \" + \"\\n- \".join(failed_descriptions) + \"\\n\\n\"\n",
    "        f\"Please generate a new response that satisfies ALL requirements.\"\n",
    "    )\n",
    "\n",
    "\n",
    "result = external_ivr(\n",
    "    generate_fn=mock_generate,\n",
    "    requirements=requirements,\n",
    "    backend=backend,\n",
    "    initial_context=initial_context,\n",
    "    loop_budget=3,\n",
    "    repair_prompt_fn=custom_repair_prompt,\n",
    ")\n",
    "\n",
    "print(f\"IVR with custom repair prompt:\")\n",
    "print(f\"  Success: {result.success}, Attempts: {result.attempts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "### Using external_ivr() with a Real LangChain Agent\n",
    "\n",
    "Here's how you would integrate `external_ivr()` with an actual LangChain agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Wrapping a LangChain agent for IVR\n",
    "# (This is a template - uncomment and modify for your use case)\n",
    "\n",
    "'''\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# Create your LangChain agent\n",
    "llm = ChatOllama(model=\"granite4:latest\", temperature=0.0)\n",
    "agent = create_agent(model=llm, tools=[], system_prompt=\"You are helpful.\")\n",
    "\n",
    "def langchain_generate(messages: list[Message]) -> str:\n",
    "    \"\"\"Wrap LangChain agent for external_ivr.\"\"\"\n",
    "    # Convert Mellea messages to LangChain format\n",
    "    lc_messages = [\n",
    "        {\"role\": m.role, \"content\": m.content}\n",
    "        for m in messages\n",
    "    ]\n",
    "    result = agent.invoke({\"messages\": lc_messages})\n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "# Run IVR with the LangChain agent\n",
    "result = external_ivr(\n",
    "    generate_fn=langchain_generate,\n",
    "    requirements=[\"Must be helpful\", \"Must answer the question\"],\n",
    "    backend=backend,\n",
    "    initial_context=[{\"role\": \"user\", \"content\": \"What is Python?\"}],\n",
    "    loop_budget=3,\n",
    ")\n",
    "'''\n",
    "\n",
    "print(\"See the code cell above for a LangChain integration template.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"formats\"></a>\n",
    "## Supported Formats\n",
    "\n",
    "The External Validation API auto-detects and handles multiple formats:\n",
    "\n",
    "### Output Formats\n",
    "\n",
    "| Format | Example |\n",
    "|--------|----------|\n",
    "| String | `\"The answer is 42.\"` |\n",
    "| OpenAI dict | `{\"role\": \"assistant\", \"content\": \"...\"}` |\n",
    "| LangChain message | `AIMessage(content=\"...\")` |\n",
    "| Mellea Message | `Message(role=\"assistant\", content=\"...\")` |\n",
    "| ModelOutputThunk | `ModelOutputThunk(value=\"...\")` |\n",
    "\n",
    "### Context Formats\n",
    "\n",
    "| Format | Example |\n",
    "|--------|----------|\n",
    "| OpenAI list | `[{\"role\": \"user\", \"content\": \"...\"}]` |\n",
    "| LangChain list | `[HumanMessage(content=\"...\")]` |\n",
    "| Mellea list | `[Message(role=\"user\", content=\"...\")]` |\n",
    "\n",
    "### Requirement Formats\n",
    "\n",
    "| Format | Validation Type |\n",
    "|--------|----------------|\n",
    "| String | LLM-as-judge (uses backend) |\n",
    "| `req(description)` | LLM-as-judge |\n",
    "| `req(description, validation_fn=...)` | Programmatic |\n",
    "| `req(description, validation_fn=simple_validate(...))` | Programmatic (lambda) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate format auto-detection\n",
    "test_outputs = [\n",
    "    (\"string\", \"Hello world\"),\n",
    "    (\"OpenAI dict\", {\"role\": \"assistant\", \"content\": \"Hello world\"}),\n",
    "    (\"Mellea Message\", Message(role=\"assistant\", content=\"Hello world\")),\n",
    "]\n",
    "\n",
    "if HAS_LANGCHAIN:\n",
    "    test_outputs.append((\"LangChain\", AIMessage(content=\"Hello world\")))\n",
    "\n",
    "print(\"Format Auto-Detection Test:\")\n",
    "for format_name, output in test_outputs:\n",
    "    results = external_validate(\n",
    "        output=output, requirements=[\"Must contain a greeting\"], backend=backend\n",
    "    )\n",
    "    status = \"PASS\" if results[0].as_bool() else \"FAIL\"\n",
    "    print(f\"  [{status}] {format_name}: {type(output).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"summary\"></a>\n",
    "## Summary\n",
    "\n",
    "### API Reference\n",
    "\n",
    "```python\n",
    "from mellea import external_validate, ExternalSession\n",
    "from mellea.stdlib.interop import external_ivr, IVRResult\n",
    "```\n",
    "\n",
    "### Quick Reference\n",
    "\n",
    "| Function/Class | Use Case |\n",
    "|---------------|----------|\n",
    "| `external_validate()` | One-shot validation of any output format |\n",
    "| `ExternalSession.from_output()` | Session from output + optional context |\n",
    "| `ExternalSession.from_openai()` | Session from OpenAI message list |\n",
    "| `ExternalSession.from_langchain()` | Session from LangChain message list |\n",
    "| `session.validate()` | Validate against requirements |\n",
    "| `session.all_passed()` | Quick boolean check |\n",
    "| `external_ivr()` | Full IVR loop with automatic retries |\n",
    "\n",
    "### Key Benefits\n",
    "\n",
    "1. **Format Agnostic**: Works with strings, OpenAI dicts, LangChain messages, or Mellea types\n",
    "2. **Simple API**: One function call vs. manual context building\n",
    "3. **Full Validation**: Supports both programmatic and LLM-as-judge validation\n",
    "4. **IVR Support**: Built-in retry loop with customizable repair prompts\n",
    "5. **Async Support**: All functions have async variants (`aexternal_validate`, `aexternal_ivr`)\n",
    "\n",
    "### Comparison with Manual Approach\n",
    "\n",
    "**Before (Manual):**\n",
    "```python\n",
    "from mellea.core.base import ModelOutputThunk\n",
    "from mellea.stdlib.context import ChatContext\n",
    "from mellea.stdlib.components.chat_converters import langchain_messages_to_mellea\n",
    "\n",
    "# Convert context\n",
    "mellea_messages = langchain_messages_to_mellea(lc_messages[:-1])\n",
    "ctx = ChatContext()\n",
    "for msg in mellea_messages:\n",
    "    ctx = ctx.add(msg)\n",
    "\n",
    "# Wrap output\n",
    "thunk = ModelOutputThunk(value=lc_messages[-1].content)\n",
    "ctx = ctx.add(thunk)\n",
    "\n",
    "# Validate\n",
    "m = mellea.start_session(ctx=ctx)\n",
    "results = m.validate(requirements)\n",
    "```\n",
    "\n",
    "**After (External Validation API):**\n",
    "```python\n",
    "from mellea import external_validate\n",
    "\n",
    "results = external_validate(\n",
    "    output=lc_messages[-1],\n",
    "    requirements=[\"Must be helpful\"],\n",
    "    backend=backend,\n",
    "    context=lc_messages[:-1],\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
