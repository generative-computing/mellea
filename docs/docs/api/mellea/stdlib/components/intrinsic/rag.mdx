---
title: "mellea.stdlib.components.intrinsic.rag"
sidebarTitle: "mellea.stdlib.components.intrinsic.rag"
description: "Intrinsic functions related to retrieval-augmented generation."
---





import { SidebarFix } from "/snippets/SidebarFix.mdx";

<SidebarFix />

## Functions

<div className="w-full h-px bg-gray-200 dark:bg-gray-700 my-4" />


### <span className="ml-2 inline-flex items-center rounded-full px-2 py-1 text-[0.7rem] font-bold tracking-wide bg-[#3064E3]/20 text-[#1D4ED8]">FUNC</span> `check_answerability` <sup><a href="https://github.com/generative-computing/mellea/blob/main/mellea/stdlib/components/intrinsic/rag.py#L81" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
check_answerability(question: str, documents: collections.abc.Iterable[Document], context: ChatContext, backend: AdapterMixin) -> float
```


Test a user's question for answerability.

Intrinsic function that checks whether the question in the last user turn of a
chat can be answered by a provided set of RAG documents.

:param context: Chat context containing the conversation thus far
:param question: Question that the user has posed in response to the last turn in
    ``context``.
:param documents: Document snippets retrieved that may or may not answer the
    indicated question.
:param backend: Backend instance that supports adding the LoRA or aLoRA adapters
    for answerability checks

:return: Answerability score as a floating-point value from 0 to 1.


<div className="w-full h-px bg-gray-200 dark:bg-gray-700 my-4" />

### <span className="ml-2 inline-flex items-center rounded-full px-2 py-1 text-[0.7rem] font-bold tracking-wide bg-[#3064E3]/20 text-[#1D4ED8]">FUNC</span> `rewrite_question` <sup><a href="https://github.com/generative-computing/mellea/blob/main/mellea/stdlib/components/intrinsic/rag.py#L110" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
rewrite_question(question: str, context: ChatContext, backend: AdapterMixin) -> float
```


Rewrite a user's question for retrieval.

Intrinsic function that rewrites the question in the next user turn into a
self-contained query that can be passed to the retriever.

:param context: Chat context containing the conversation thus far
:param question: Question that the user has posed in response to the last turn in
    ``context``.
:param backend: Backend instance that supports adding the LoRA or aLoRA adapters

:return: Rewritten version of ``question``.


<div className="w-full h-px bg-gray-200 dark:bg-gray-700 my-4" />

### <span className="ml-2 inline-flex items-center rounded-full px-2 py-1 text-[0.7rem] font-bold tracking-wide bg-[#3064E3]/20 text-[#1D4ED8]">FUNC</span> `find_citations` <sup><a href="https://github.com/generative-computing/mellea/blob/main/mellea/stdlib/components/intrinsic/rag.py#L131" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
find_citations(response: str, documents: collections.abc.Iterable[Document], context: ChatContext, backend: AdapterMixin) -> list[dict]
```


Find information in documents that supports an assistant response.

Intrinsic function that finds sentences in RAG documents that support sentences
in a potential assistant response to a user question.

:param context: Context of the dialog between user and assistant at the point where
    the user has just asked a question that will be answered with RAG documents
:param response: Potential assistant response
:param documents: Documents at were used to generate ``response``. These documents
    should set the ``doc_id`` field; otherwise the intrinsic will be unable to
    specify which document was the source of a given citation.
:param backend: Backend that supports one of the adapters that implements this
    intrinsic.
:return: List of records with the following fields:
    * ``response_begin``
    * ``response_end``
    * ``response_text``
    * ``citation_doc_id``
    * ``citation_begin``
    * ``citation_end``
    * ``citation_text``
Begin and end offsets are character offsets into their respective UTF-8 strings.


<div className="w-full h-px bg-gray-200 dark:bg-gray-700 my-4" />

### <span className="ml-2 inline-flex items-center rounded-full px-2 py-1 text-[0.7rem] font-bold tracking-wide bg-[#3064E3]/20 text-[#1D4ED8]">FUNC</span> `check_context_relevance` <sup><a href="https://github.com/generative-computing/mellea/blob/main/mellea/stdlib/components/intrinsic/rag.py#L168" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
check_context_relevance(question: str, document: Document, context: ChatContext, backend: AdapterMixin) -> float
```


Test whether a document is relevant to a user's question.

Intrinsic function that checks whether a single document contains part or all of
the answer to a user's question. Does not consider the context in which the
question was asked.

:param context: The chat up to the point where the user asked a question.
:param question: Question that the user has posed.
:param document: A retrieved document snippet
:param backend: Backend instance that supports the adapters that implement this
    intrinsic

:return: Context relevance score as a floating-point value from 0 to 1.


<div className="w-full h-px bg-gray-200 dark:bg-gray-700 my-4" />

### <span className="ml-2 inline-flex items-center rounded-full px-2 py-1 text-[0.7rem] font-bold tracking-wide bg-[#3064E3]/20 text-[#1D4ED8]">FUNC</span> `flag_hallucinated_content` <sup><a href="https://github.com/generative-computing/mellea/blob/main/mellea/stdlib/components/intrinsic/rag.py#L195" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
flag_hallucinated_content(response: str, documents: collections.abc.Iterable[Document], context: ChatContext, backend: AdapterMixin) -> float
```


Flag potentially-hallucinated sentences in an agent's response.

Intrinsic function that checks whether the sentences in an agent's response to a
user question are faithful to the retrieved document snippets. Sentences that do not
align with the retrieved snippets are flagged as potential hallucinations.

:param context: A chat log that ends with a user asking a question
:param response: The assistant's response to the user's question in the last turn
    of ``context``
:param documents: Document snippets that were used to generate ``response``
:param backend: Backend instance that supports the adapters that implement this
    intrinsic

:return: List of records with the following fields:
    * response_begin
    * response_end
    * response_text
    * faithfulness_likelihood
    * explanation


<div className="w-full h-px bg-gray-200 dark:bg-gray-700 my-4" />

### <span className="ml-2 inline-flex items-center rounded-full px-2 py-1 text-[0.7rem] font-bold tracking-wide bg-[#3064E3]/20 text-[#1D4ED8]">FUNC</span> `rewrite_answer_for_relevance` <sup><a href="https://github.com/generative-computing/mellea/blob/main/mellea/stdlib/components/intrinsic/rag.py#L229" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
rewrite_answer_for_relevance(rewrite_threshold: float = 0.5) -> str
```


Rewrite an assistant answer to improve relevance to the user's question.

:param context: A chat log that ends with a user asking a question
:param response: The assistant's response to the user's question in the last turn
    of ``context``
:param documents: Document snippets that were used to generate ``response``
:param backend: Backend instance that supports the adapters that implement this
    intrinsic
:param rewrite_threshold: Number between 0.0 and 1.0 that determines how eagerly
    to skip rewriting the assistant's answer for relevance. 0.0 means never rewrite
    and 1.0 means always rewrite.

:returns: Either the original response, or a rewritten version of the original
    response.

<div className="w-full h-px bg-gray-200 dark:bg-gray-700 my-4" />
