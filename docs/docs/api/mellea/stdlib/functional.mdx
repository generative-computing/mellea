---
title: "mellea.stdlib.functional"
sidebarTitle: "mellea.stdlib.functional"
description: "Functions for Mellea operations like Instruct, Chat, etc..."
---





import { SidebarFix } from "/snippets/SidebarFix.mdx";

<SidebarFix />

## Functions

<div className="w-full h-px bg-gray-200 dark:bg-gray-700 my-4" />


### <span className="ml-2 inline-flex items-center rounded-full px-2 py-1 text-[0.7rem] font-bold tracking-wide bg-[#3064E3]/20 text-[#1D4ED8]">FUNC</span> `act` <sup><a href="https://github.com/generative-computing/mellea/blob/main/mellea/stdlib/functional.py#L64" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
act(action: Component[S], context: Context, backend: Backend) -> tuple[ModelOutputThunk[S], Context] | SamplingResult[S]
```


Runs a generic action, and adds both the action and the result to the context.

**Args:**
- `action`: the Component from which to generate.
- `context`: the context being used as a history from which to generate the response.
- `backend`: the backend used to generate the response.
- `requirements`: used as additional requirements when a sampling strategy is provided.
- `strategy`: a SamplingStrategy that describes the strategy for validating and repairing/retrying for the instruct-validate-repair pattern. None means that no particular sampling strategy is used.
- `return_sampling_results`: attach the (successful and failed) sampling attempts to the results.
- `format`: if set, the BaseModel to use for constrained decoding.
- `model_options`: additional model options, which will upsert into the model/backend's defaults.
- `tool_calls`: if true, tool calling is enabled.

**Returns:**
- A (ModelOutputThunk, Context) if `return_sampling_results` is `False`, else returns a `SamplingResult`.


<div className="w-full h-px bg-gray-200 dark:bg-gray-700 my-4" />

### <span className="ml-2 inline-flex items-center rounded-full px-2 py-1 text-[0.7rem] font-bold tracking-wide bg-[#3064E3]/20 text-[#1D4ED8]">FUNC</span> `instruct` <sup><a href="https://github.com/generative-computing/mellea/blob/main/mellea/stdlib/functional.py#L153" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
instruct(description: str, context: Context, backend: Backend) -> tuple[ModelOutputThunk[str], Context] | SamplingResult[str]
```


Generates from an instruction.

**Args:**
- `description`: The description of the instruction.
- `context`: the context being used as a history from which to generate the response.
- `backend`: the backend used to generate the response.
- `requirements`: A list of requirements that the instruction can be validated against.
- `icl_examples`: A list of in-context-learning examples that the instruction can be validated against.
- `grounding_context`: A list of grounding contexts that the instruction can use. They can bind as variables using a (key\: str, value\: str | ContentBlock) tuple.
- `user_variables`: A dict of user-defined variables used to fill in Jinja placeholders in other parameters. This requires that all other provided parameters are provided as strings.
- `prefix`: A prefix string or ContentBlock to use when generating the instruction.
- `output_prefix`: A string or ContentBlock that defines a prefix for the output generation. Usually you do not need this.
- `strategy`: A SamplingStrategy that describes the strategy for validating and repairing/retrying for the instruct-validate-repair pattern. None means that no particular sampling strategy is used.
- `return_sampling_results`: attach the (successful and failed) sampling attempts to the results.
- `format`: If set, the BaseModel to use for constrained decoding.
- `model_options`: Additional model options, which will upsert into the model/backend's defaults.
- `tool_calls`: If true, tool calling is enabled.
- `images`: A list of images to be used in the instruction or None if none.

**Returns:**
- A (ModelOutputThunk, Context) if `return_sampling_results` is `False`, else returns a `SamplingResult`.


<div className="w-full h-px bg-gray-200 dark:bg-gray-700 my-4" />

### <span className="ml-2 inline-flex items-center rounded-full px-2 py-1 text-[0.7rem] font-bold tracking-wide bg-[#3064E3]/20 text-[#1D4ED8]">FUNC</span> `chat` <sup><a href="https://github.com/generative-computing/mellea/blob/main/mellea/stdlib/functional.py#L224" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
chat(content: str, context: Context, backend: Backend) -> tuple[Message, Context]
```


Sends a simple chat message and returns the response. Adds both messages to the Context.


<div className="w-full h-px bg-gray-200 dark:bg-gray-700 my-4" />

### <span className="ml-2 inline-flex items-center rounded-full px-2 py-1 text-[0.7rem] font-bold tracking-wide bg-[#3064E3]/20 text-[#1D4ED8]">FUNC</span> `validate` <sup><a href="https://github.com/generative-computing/mellea/blob/main/mellea/stdlib/functional.py#L261" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
validate(reqs: Requirement | list[Requirement], context: Context, backend: Backend) -> list[ValidationResult]
```


Validates a set of requirements over the output (if provided) or the current context (if the output is not provided).


<div className="w-full h-px bg-gray-200 dark:bg-gray-700 my-4" />

### <span className="ml-2 inline-flex items-center rounded-full px-2 py-1 text-[0.7rem] font-bold tracking-wide bg-[#3064E3]/20 text-[#1D4ED8]">FUNC</span> `query` <sup><a href="https://github.com/generative-computing/mellea/blob/main/mellea/stdlib/functional.py#L293" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
query(obj: Any, query: str, context: Context, backend: Backend) -> tuple[ModelOutputThunk, Context]
```


Query method for retrieving information from an object.

**Args:**
- `obj `: The object to be queried. It should be an instance of MObject or can be converted to one if necessary.
- `query`: The string representing the query to be executed against the object.
- `context`: the context being used as a history from which to generate the response.
- `backend`: the backend used to generate the response.
- `format`: format for output parsing.
- `model_options`: Model options to pass to the backend.
- `tool_calls`: If true, the model may make tool calls. Defaults to False.

**Returns:**
- The result of the query as processed by the backend.


<div className="w-full h-px bg-gray-200 dark:bg-gray-700 my-4" />

### <span className="ml-2 inline-flex items-center rounded-full px-2 py-1 text-[0.7rem] font-bold tracking-wide bg-[#3064E3]/20 text-[#1D4ED8]">FUNC</span> `transform` <sup><a href="https://github.com/generative-computing/mellea/blob/main/mellea/stdlib/functional.py#L335" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
transform(obj: Any, transformation: str, context: Context, backend: Backend) -> tuple[ModelOutputThunk | Any, Context]
```


Transform method for creating a new object with the transformation applied.

**Args:**
- `obj`: The object to be queried. It should be an instance of MObject or can be converted to one if necessary.
- `transformation`: The string representing the query to be executed against the object.
- `context`: the context being used as a history from which to generate the response.
- `backend`: the backend used to generate the response.
- `format`: format for output parsing; usually not needed with transform.
- `model_options`: Model options to pass to the backend.

**Returns:**
- The result of the transformation as processed by the backend. If no tools were called,
- the return type will be always be (ModelOutputThunk, Context). If a tool was called, the return type will be the return type
- of the function called, usually the type of the object passed in.


<div className="w-full h-px bg-gray-200 dark:bg-gray-700 my-4" />

### <span className="ml-2 inline-flex items-center rounded-full px-2 py-1 text-[0.7rem] font-bold tracking-wide bg-[#3064E3]/20 text-[#1D4ED8]">FUNC</span> `aact` <sup><a href="https://github.com/generative-computing/mellea/blob/main/mellea/stdlib/functional.py#L448" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
aact(action: Component[S], context: Context, backend: Backend) -> tuple[ModelOutputThunk[S], Context] | SamplingResult
```


Asynchronous version of .act; runs a generic action, and adds both the action and the result to the context.

**Args:**
- `action`: the Component from which to generate.
- `context`: the context being used as a history from which to generate the response.
- `backend`: the backend used to generate the response.
- `requirements`: used as additional requirements when a sampling strategy is provided
- `strategy`: a SamplingStrategy that describes the strategy for validating and repairing/retrying for the instruct-validate-repair pattern. None means that no particular sampling strategy is used.
- `return_sampling_results`: attach the (successful and failed) sampling attempts to the results.
- `format`: if set, the BaseModel to use for constrained decoding.
- `model_options`: additional model options, which will upsert into the model/backend's defaults.
- `tool_calls`: if true, tool calling is enabled.
- `silence_context_type_warning`: if called directly from an asynchronous function, will log a warning if not using a SimpleContext

**Returns:**
- A (ModelOutputThunk, Context) if `return_sampling_results` is `False`, else returns a `SamplingResult`.


<div className="w-full h-px bg-gray-200 dark:bg-gray-700 my-4" />

### <span className="ml-2 inline-flex items-center rounded-full px-2 py-1 text-[0.7rem] font-bold tracking-wide bg-[#3064E3]/20 text-[#1D4ED8]">FUNC</span> `ainstruct` <sup><a href="https://github.com/generative-computing/mellea/blob/main/mellea/stdlib/functional.py#L591" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
ainstruct(description: str, context: Context, backend: Backend) -> tuple[ModelOutputThunk[str], Context] | SamplingResult
```


Generates from an instruction.

**Args:**
- `description`: The description of the instruction.
- `context`: the context being used as a history from which to generate the response.
- `backend`: the backend used to generate the response.
- `requirements`: A list of requirements that the instruction can be validated against.
- `icl_examples`: A list of in-context-learning examples that the instruction can be validated against.
- `grounding_context`: A list of grounding contexts that the instruction can use. They can bind as variables using a (key\: str, value\: str | ContentBlock) tuple.
- `user_variables`: A dict of user-defined variables used to fill in Jinja placeholders in other parameters. This requires that all other provided parameters are provided as strings.
- `prefix`: A prefix string or ContentBlock to use when generating the instruction.
- `output_prefix`: A string or ContentBlock that defines a prefix for the output generation. Usually you do not need this.
- `strategy`: A SamplingStrategy that describes the strategy for validating and repairing/retrying for the instruct-validate-repair pattern. None means that no particular sampling strategy is used.
- `return_sampling_results`: attach the (successful and failed) sampling attempts to the results.
- `format`: If set, the BaseModel to use for constrained decoding.
- `model_options`: Additional model options, which will upsert into the model/backend's defaults.
- `tool_calls`: If true, tool calling is enabled.
- `images`: A list of images to be used in the instruction or None if none.

**Returns:**
- A (ModelOutputThunk, Context) if `return_sampling_results` is `False`, else returns a `SamplingResult`.


<div className="w-full h-px bg-gray-200 dark:bg-gray-700 my-4" />

### <span className="ml-2 inline-flex items-center rounded-full px-2 py-1 text-[0.7rem] font-bold tracking-wide bg-[#3064E3]/20 text-[#1D4ED8]">FUNC</span> `achat` <sup><a href="https://github.com/generative-computing/mellea/blob/main/mellea/stdlib/functional.py#L662" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
achat(content: str, context: Context, backend: Backend) -> tuple[Message, Context]
```


Sends a simple chat message and returns the response. Adds both messages to the Context.


<div className="w-full h-px bg-gray-200 dark:bg-gray-700 my-4" />

### <span className="ml-2 inline-flex items-center rounded-full px-2 py-1 text-[0.7rem] font-bold tracking-wide bg-[#3064E3]/20 text-[#1D4ED8]">FUNC</span> `avalidate` <sup><a href="https://github.com/generative-computing/mellea/blob/main/mellea/stdlib/functional.py#L699" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
avalidate(reqs: Requirement | list[Requirement], context: Context, backend: Backend) -> list[ValidationResult]
```


Asynchronous version of .validate; validates a set of requirements over the output (if provided) or the current context (if the output is not provided).


<div className="w-full h-px bg-gray-200 dark:bg-gray-700 my-4" />

### <span className="ml-2 inline-flex items-center rounded-full px-2 py-1 text-[0.7rem] font-bold tracking-wide bg-[#3064E3]/20 text-[#1D4ED8]">FUNC</span> `aquery` <sup><a href="https://github.com/generative-computing/mellea/blob/main/mellea/stdlib/functional.py#L756" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
aquery(obj: Any, query: str, context: Context, backend: Backend) -> tuple[ModelOutputThunk, Context]
```


Query method for retrieving information from an object.

**Args:**
- `obj `: The object to be queried. It should be an instance of MObject or can be converted to one if necessary.
- `query`: The string representing the query to be executed against the object.
- `context`: the context being used as a history from which to generate the response.
- `backend`: the backend used to generate the response.
- `format`: format for output parsing.
- `model_options`: Model options to pass to the backend.
- `tool_calls`: If true, the model may make tool calls. Defaults to False.

**Returns:**
- The result of the query as processed by the backend.


<div className="w-full h-px bg-gray-200 dark:bg-gray-700 my-4" />

### <span className="ml-2 inline-flex items-center rounded-full px-2 py-1 text-[0.7rem] font-bold tracking-wide bg-[#3064E3]/20 text-[#1D4ED8]">FUNC</span> `atransform` <sup><a href="https://github.com/generative-computing/mellea/blob/main/mellea/stdlib/functional.py#L798" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
atransform(obj: Any, transformation: str, context: Context, backend: Backend) -> tuple[ModelOutputThunk | Any, Context]
```


Transform method for creating a new object with the transformation applied.

**Args:**
- `obj`: The object to be queried. It should be an instance of MObject or can be converted to one if necessary.
- `transformation`: The string representing the query to be executed against the object.
- `context`: the context being used as a history from which to generate the response.
- `backend`: the backend used to generate the response.
- `format`: format for output parsing; usually not needed with transform.
- `model_options`: Model options to pass to the backend.

**Returns:**
- ModelOutputThunk|Any: The result of the transformation as processed by the backend. If no tools were called,
- the return type will be always be ModelOutputThunk. If a tool was called, the return type will be the return type
- of the function called, usually the type of the object passed in.

<div className="w-full h-px bg-gray-200 dark:bg-gray-700 my-4" />
